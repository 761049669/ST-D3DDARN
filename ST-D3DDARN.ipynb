{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1924bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import networkx as nx\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from MaxMin_Norm import MinMaxNormalization\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "sys.path.append('../data_process/')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92caf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=False,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "class CoordAtt(nn.Module):\n",
    "    def __init__(self, inp, oup, reduction):\n",
    "        super(CoordAtt, self).__init__()\n",
    "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
    "\n",
    "        mip = max(8, inp // reduction)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(mip)\n",
    "        self.act = h_swish()\n",
    "\n",
    "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        n, c, h, w = x.size()\n",
    "        x_h = self.pool_h(x)\n",
    "        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n",
    "\n",
    "        y = torch.cat([x_h, x_w], dim=2)\n",
    "        \n",
    "        y = self.conv1(y)\n",
    "        y = self.bn1(y)\n",
    "        y = self.act(y)\n",
    "    \n",
    "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
    "        x_w = x_w.permute(0, 1, 3, 2)\n",
    "        \n",
    "        a_h = self.conv_h(x_h).sigmoid()\n",
    "        a_w = self.conv_w(x_w).sigmoid()\n",
    "# 如果下面这个原论文代码用不了的话，可以换成另一个试试\n",
    "        out = identity * a_w * a_h \n",
    "        # out = a_h.expand_as(x) * a_w.expand_as(x) * identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997b07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, lng, lat):\n",
    "        # 模型的输入是一个四维张量 (B, C, lng, lat)\n",
    "        super(ResUnit, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(60)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(60)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.CoordAtt = CoordAtt(60,60,4)        \n",
    "        self.fc = nn.Linear(1024, 128)\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc0 = nn.Linear(128, 1024)\n",
    "        # 分别定义两个批归一化层和卷积层\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.bn1(x))\n",
    "        z = self.conv1(z)\n",
    "        z = F.relu(self.bn2(z))\n",
    "        z = self.conv2(z)\n",
    "        z = z.reshape(-1,60,1024)\n",
    "        Qs = self.fc(z)\n",
    "        Ks = self.fc1(z).permute(0, 2, 1) \n",
    "        Vs = self.fc2(z)\n",
    "        attention_scores = torch.matmul(Qs, Ks)\n",
    "        attention_scores = attention_scores / math.sqrt(61440)\n",
    "        attention_scores = nn.Softmax(dim=-1)(attention_scores)\n",
    "        z = torch.matmul(attention_scores, Vs)\n",
    "        z = self.fc0(z)\n",
    "        z = z.reshape(-1,60,32,32)\n",
    "        z = self.CoordAtt(z)\n",
    "        out = x+z\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004e8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch_net(nn.Module):\n",
    "    def __init__(self, num_res_unit, input_lenght, flow_channel, grid_heigh, grid_width,in_channels):\n",
    "        super(Branch_net, self).__init__()\n",
    "        self.num_res_unit = num_res_unit\n",
    "        self.input_lenght = input_lenght\n",
    "        self.flow_channel = flow_channel\n",
    "        self.grid_heigh = grid_heigh\n",
    "        self.grid_width = grid_width\n",
    "        self.in_channels = in_channels\n",
    "        # 每个分支网络的首部都是用一个卷积网络将输入的特征维度从低维映射到高维\n",
    "        self.branch_net = nn.ModuleList([ResUnit(60, 60, self.grid_heigh, self.grid_width)])\n",
    "        # 接下来依次添加多个残差卷积单元\n",
    "        for i in range(1): \n",
    "            self.branch_net.append(ResUnit(60, 60, self.grid_heigh, self.grid_width))\n",
    "        self.branch_net.append(nn.Conv2d(60, 2, kernel_size=3,stride = 1, padding = 1))\n",
    "    # 分支网络的前向传播\n",
    "    def forward(self, x):\n",
    "        for layer in self.branch_net:\n",
    "             x = layer(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef0a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEResUnit1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, i):\n",
    "        super(STEResUnit1,self).__init__()\n",
    "        self.i=i\n",
    "        self.conv3d0  = nn.Conv3d(in_channels, out_channels, kernel_size=(1,3,3), dilation =(1,1,1), stride=1, padding='same')\n",
    "        self.conv3d00  = nn.Conv3d(out_channels, out_channels, kernel_size=(3,1,1), dilation =(1,1,1), stride=1, padding='same')\n",
    "        self.conv1 = nn.Conv3d(out_channels, 2, kernel_size=(1,1,1), dilation =(1,1,1),stride=1, padding='same')\n",
    "    def forward(self,x):\n",
    "        x0 = self.conv3d0(x)\n",
    "        X = self.conv3d00(x0)\n",
    "        if self.i ==True:\n",
    "            X = self.conv1(X)\n",
    "            return X\n",
    "        else:\n",
    "            return torch.cat((X,x),1)\n",
    "class DenseNet(nn.Sequential):\n",
    "    \"\"\"DenseBlock\"\"\"\n",
    "    def __init__(self, num_layers, num_input_features,num_output):\n",
    "        super(DenseNet, self).__init__() \n",
    "        for i in range(num_layers):\n",
    "            r = False\n",
    "            if i ==num_layers-1:\n",
    "                r = True\n",
    "            layer = STEResUnit1(num_input_features+i*num_output, num_output,r)\n",
    "            self.add_module(\"denselayer%d\" % (i+1), layer)\n",
    "    def forward(self, x):\n",
    "        out = super(DenseNet, self).forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97233ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,lr=0.01,epoch=10, #训练轮次数\n",
    "                 batch_size=32, #批训练batch大小\n",
    "                 c_length=3, #邻近性时间流量特征序列默认长度\n",
    "                 p_length=348654684896, #周期性时间流量特征序列默认长度\n",
    "                 t_length=2,  #趋势性时间流量特征序列默认长度\n",
    "                 external_dim=28, #外部特征的维度\n",
    "                 grid_heigh=32, #网格图的高度\n",
    "                 grid_width=32, #网格图的宽度\n",
    "                 flow_channel=2, #流量种类\n",
    "                 num_res_unit=2, #设定残差卷积单元的数量\n",
    "                 in_channels = 6,\n",
    "                 data_min = -10000,  # 输入数据的最小值默认值\n",
    "                 data_max = 10000):\n",
    "        super(Model, self).__init__()\n",
    "        self.epoch = epoch  \n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.c_length = c_length\n",
    "        self.p_length = p_length\n",
    "        self.t_length = t_length\n",
    "        self.external_dim = external_dim\n",
    "        self.grid_heigh = grid_heigh\n",
    "        self.grid_width = grid_width\n",
    "        self.in_channels = in_channels\n",
    "        self.flow_channel  = flow_channel \n",
    "        self.num_res_unit = num_res_unit\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.data_min = data_min\n",
    "        self.data_max = data_max\n",
    "        self.gpu_available = torch.cuda.is_available()\n",
    "        if self.gpu_available:  #如果GPU存在，则调用\n",
    "            self.gpu = torch.device(\"cuda:0\")\n",
    "        self.backbone_net()\n",
    "        self.save_path=\"L%d_C%d_P%d_T%d/\"% (self.num_res_unit,self.c_length, self.p_length, self.t_length)\n",
    "        self.best_mse = 10000\n",
    "    def backbone_net(self):\n",
    "        self.c_net = Branch_net(self.num_res_unit,self.c_length,\n",
    "                     self.flow_channel, self.grid_heigh, self.grid_width,60) \n",
    "        self.conv3D1 = nn.Conv3d(2, 8, kernel_size=(1,1,1), stride=1, padding='same')\n",
    "        self.conv3D11 = nn.Conv3d(2, 8, kernel_size=(1,1,1), stride=1, padding='same')\n",
    "        self.conv3D111 = nn.Conv3d(2, 8, kernel_size=(1,1,1), stride=1, padding='same')\n",
    "        self.conv3D222 = nn.Conv3d(8, 2, kernel_size=(1,1,1), stride=1, padding='same')\n",
    "        self.conv3D22 = nn.Conv3d(8, 2, kernel_size=(1,1,1), stride=1, padding='same')\n",
    "        self.DenseNet = DenseNet(4,8,8)\n",
    "        self.conv1 = nn.Conv2d(19, 60, 3, 1, 1)\n",
    "        self.ext_net1 = nn.Sequential(\n",
    "            nn.Linear(28, 15), \n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(15,1*self.grid_heigh*self.grid_width))\n",
    "        self.lstm = LSTM(28,32,1,28)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, xc, xp, xt, ext,xw):\n",
    "        ext = self.lstm(ext)\n",
    "        ext = self.dropout(ext)\n",
    "        ext = self.ext_net1(ext).view([-1, 1,\n",
    "                                          self.grid_heigh, self.grid_width])\n",
    "        xcin = xc[:,0:11:2,:,:] #clossness\n",
    "        xcin = xcin.reshape(-1,1,6,32,32)\n",
    "        xcout = xc[:,1:12:2,:,:]\n",
    "        xcout = xcout.reshape(-1,1,6,32,32)\n",
    "        Xc = torch.cat((xcin,xcout),1)\n",
    "        \n",
    "        xpin = xp[:,:5:2,:,:] #period\n",
    "        xpin = xpin.reshape(-1,1,3,32,32)\n",
    "        xpout = xp[:,1:6:2,:,:]\n",
    "        xpout = xpout.reshape(-1,1,3,32,32)\n",
    "        Xp = torch.cat((xpin,xpout),1)\n",
    "        \n",
    "        xtin = xt[:,:5:2,:,:] #trend\n",
    "        xtin = xtin.reshape(-1,1,3,32,32)\n",
    "        xtout = xt[:,1:6:2,:,:]\n",
    "        xtout = xtout.reshape(-1,1,3,32,32)\n",
    "        \n",
    "        Xt = torch.cat((xtin,xtout),1)\n",
    "        Xc = self.conv3D1(Xc)\n",
    "        Xc = self.DenseNet(Xc)\n",
    "        Xc = Xc.reshape(-1,12,32,32)\n",
    "        Xp = self.conv3D11(Xp)\n",
    "        Xp = self.conv3D22(Xp)\n",
    "        Xp = Xp.reshape(-1,6,32,32)\n",
    "        Xt = self.conv3D111(Xt)\n",
    "        Xt = self.conv3D222(Xt)\n",
    "        Xt = Xt.reshape(-1,6,32,32)\n",
    "\n",
    "        XC = torch.cat((Xc,Xp,Xt,ext),1)\n",
    "        XC = self.conv1(XC)\n",
    "        XC = self.c_net(XC)\n",
    "        XC = torch.tanh(XC)    \n",
    "        return XC\n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        optimizer = optim.Adam(self.parameters(),lr = self.lr)\n",
    "        loss_func = nn.MSELoss() # 定义模型的优化器和损失函数\n",
    "#         loss_func = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "        early_stop_threshold = 10 # 设定提前停止阈值\n",
    "        epoch_count = 0\n",
    "        start_time = time.time()\n",
    "        for ep in range(self.epoch):\n",
    "            loss_list = []\n",
    "            rmse_list = []\n",
    "            mae_list = []\n",
    "            self.train() # 启动模型训练\n",
    "            for i, (xc, xp, xt, xe, xw,y) in enumerate(train_loader):\n",
    "                if self.gpu_available:\n",
    "                    xc = xc.to(self.gpu)\n",
    "                    xp = xp.to(self.gpu)\n",
    "                    xt = xt.to(self.gpu)\n",
    "                    xe = xe.to(self.gpu)\n",
    "                    xw = xw.to(self.gpu)\n",
    "                    y = y.to(self.gpu)\n",
    "                ypred = self.forward(xc, xp, xt, xe,xw)\n",
    "                loss = loss_func(ypred, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # 模型验证部分，根据验证集上的损失保存最优模型\n",
    "            for i, (xc, xp, xt, xe,xw, y) in enumerate(val_loader):\n",
    "                if self.gpu_available:\n",
    "                    xc = xc.to(self.gpu)\n",
    "                    xp = xp.to(self.gpu)\n",
    "                    xt = xt.to(self.gpu)\n",
    "                    xe = xe.to(self.gpu)\n",
    "                    xw = xw.to(self.gpu)\n",
    "                    y = y.to(self.gpu)\n",
    "                ypred = self.forward(xc, xp, xt, xe,xw)\n",
    "                val_loss = loss_func(ypred, y)\n",
    "                loss_list.append(val_loss.item())\n",
    "                end_time = time.time() \n",
    "            val_mse = np.mean(loss_list)\n",
    "            print(\"[%.2fs] ep %d val mse %.6f\" %(end_time - start_time, ep, val_mse))\n",
    "            if val_mse < self.best_mse: #保存当前更优模型参数\n",
    "                self.save_model(\"ST-D3DDARN\")\n",
    "                self.best_mse = val_mse\n",
    "                epoch_count = 0\n",
    "            else:\n",
    "                epoch_count = epoch_count +1\n",
    "#             if epoch_count >= early_stop_threshold:\n",
    "#                 break  # 当超过提前停止阈值时整个循环结束\n",
    "            self.eval()\n",
    "            for i, (xc, xp, xt, xe,xw, y) in enumerate(test_loader):\n",
    "                if self.gpu_available:\n",
    "                    xc = xc.to(self.gpu)\n",
    "                    xp = xp.to(self.gpu)\n",
    "                    xt = xt.to(self.gpu)\n",
    "                    xe = xe.to(self.gpu)\n",
    "                    xw = xw.to(self.gpu)\n",
    "                    y = y.to(self.gpu)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    ypred = self.forward(xc, xp, xt, xe,xw)\n",
    "                # 采用RMSE和MAE作为模型评估的指标\n",
    "#                 rmse = ((ypred - y) **2).mean().pow(1/2)\n",
    "#                 mae = ((ypred - y).abs()).mean()\n",
    "#                 # 将RMSE和MAE恢复到规范化之前的尺度\n",
    "#                 rmse = rmse * (self.data_max - self.data_min)\n",
    "#                 mae = mae * (self.data_max - self.data_min)\n",
    "#                 rmse_list.append(rmse.item())\n",
    "#                 mae_list.append(mae.item())\n",
    "                ypred = ypred.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "                if i == 0:\n",
    "                    ypred1 = ypred\n",
    "                    y1 = y\n",
    "                else:\n",
    "                    y1 = np.concatenate((y1,y),axis=0)\n",
    "                    ypred1 = np.concatenate((ypred1,ypred),axis=0)\n",
    "            y = [inverse_transform(d) for d in y1]\n",
    "            ypred = [inverse_transform(d) for d in ypred1]\n",
    "            y1 = np.array(y).reshape(2752512)\n",
    "            ypred1 = np.array(ypred).reshape(2752512)\n",
    "            print(np.sqrt(metrics.mean_squared_error(ypred1, y1)))\n",
    "            print(metrics.mean_absolute_error(ypred1, y1))\n",
    "            LISTRMSE.append(np.sqrt(metrics.mean_squared_error(ypred1, y1)))\n",
    "            LISTMAE.append(metrics.mean_absolute_error(ypred1, y1))\n",
    "    # 模型的评估测试集启动部分\n",
    "    def test_model(self, test_loader):\n",
    "        rmse_list = []\n",
    "        mae_list = []\n",
    "        self.eval() # 启动模型评估（固定BN层参数）\n",
    "        for i, (xc, xp, xt, xe,xw, y) in enumerate(test_loader):\n",
    "            if self.gpu_available:\n",
    "                xc = xc.to(self.gpu)\n",
    "                xp = xp.to(self.gpu)\n",
    "                xt = xt.to(self.gpu)\n",
    "                xe = xe.to(self.gpu)\n",
    "                xw = xw.to(self.gpu)\n",
    "                y = y.to(self.gpu)\n",
    "             \n",
    "            with torch.no_grad():\n",
    "                ypred = self.forward(xc, xp, xt, xe,xw)\n",
    "            # 采用RMSE和MAE作为模型评估的指标\n",
    "            rmse = ((ypred - y) **2).mean().pow(1/2)\n",
    "            mae = ((ypred - y).abs()).mean()\n",
    "            # 将RMSE和MAE恢复到规范化之前的尺度\n",
    "            rmse = rmse * (self.data_max - self.data_min)\n",
    "            mae = mae * (self.data_max - self.data_min)\n",
    "            rmse_list.append(rmse.item())\n",
    "            mae_list.append(mae.item())\n",
    "            ypred = ypred.cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            if i == 0:\n",
    "                ypred1 = ypred\n",
    "                y1 = y\n",
    "            else:\n",
    "                y1 = np.concatenate((y1,y),axis=0)\n",
    "                ypred1 = np.concatenate((ypred1,ypred),axis=0)\n",
    "        \n",
    "        mae_test = np.mean(mae_list)\n",
    "        rmse_test = np.mean(rmse_list)\n",
    "        return rmse_test, mae_test, ypred1, y1\n",
    "    \n",
    "    # 模型保存代码\n",
    "    def save_model(self, name):\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        torch.save(self.state_dict(), self.save_path + name + \".pkl\")\n",
    "    \n",
    "    # 读取已保存的模型\n",
    "    def load_model(self, name):\n",
    "        if not name.endswith(\".pkl\"):\n",
    "            name += \".pkl\"\n",
    "        self.load_state_dict(torch.load(self.save_path + name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705642b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(torch.cuda.is_available())\n",
    "if gpu_available:\n",
    "    gpu = torch.device(\"cuda:0\")\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb57da5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.12s] ep 0 val mse 0.004042\n",
      "39.851147\n",
      "23.06564\n",
      "[26.71s] ep 1 val mse 0.003146\n",
      "35.1136\n",
      "19.98656\n",
      "[39.01s] ep 2 val mse 0.002460\n",
      "29.558651\n",
      "16.640697\n",
      "[51.43s] ep 3 val mse 0.002818\n",
      "30.544802\n",
      "17.098852\n",
      "[64.34s] ep 4 val mse 0.002294\n",
      "26.902086\n",
      "15.62105\n",
      "[77.25s] ep 5 val mse 0.002125\n",
      "25.780987\n",
      "14.556032\n",
      "[90.03s] ep 6 val mse 0.002040\n",
      "25.347193\n",
      "14.401421\n",
      "[103.20s] ep 7 val mse 0.001906\n",
      "24.817684\n",
      "13.762437\n",
      "[116.45s] ep 8 val mse 0.001862\n",
      "25.702\n",
      "14.572268\n",
      "[129.24s] ep 9 val mse 0.001835\n",
      "24.429092\n",
      "13.79668\n",
      "[142.20s] ep 10 val mse 0.002397\n",
      "27.038414\n",
      "15.411413\n",
      "[154.64s] ep 11 val mse 0.001717\n",
      "23.239386\n",
      "12.853266\n",
      "[167.34s] ep 12 val mse 0.001610\n",
      "22.788239\n",
      "12.740134\n",
      "[180.30s] ep 13 val mse 0.001722\n",
      "23.840511\n",
      "13.512018\n",
      "[193.16s] ep 14 val mse 0.001620\n",
      "22.398159\n",
      "12.353111\n",
      "[205.58s] ep 15 val mse 0.001993\n",
      "26.776758\n",
      "15.597865\n",
      "[218.23s] ep 16 val mse 0.001530\n",
      "22.520975\n",
      "12.362679\n",
      "[230.74s] ep 17 val mse 0.001753\n",
      "25.850632\n",
      "14.282771\n",
      "[243.01s] ep 18 val mse 0.001410\n",
      "21.389608\n",
      "11.969367\n",
      "[255.25s] ep 19 val mse 0.001594\n",
      "22.223698\n",
      "12.105813\n",
      "[267.54s] ep 20 val mse 0.001601\n",
      "22.925318\n",
      "12.789076\n",
      "[279.93s] ep 21 val mse 0.001332\n",
      "21.33592\n",
      "12.003965\n",
      "[292.30s] ep 22 val mse 0.001506\n",
      "21.756502\n",
      "12.354082\n",
      "[304.60s] ep 23 val mse 0.001542\n",
      "22.578983\n",
      "12.719876\n",
      "[316.99s] ep 24 val mse 0.001340\n",
      "21.082067\n",
      "12.014702\n",
      "[329.52s] ep 25 val mse 0.001454\n",
      "22.396868\n",
      "12.579674\n",
      "[341.94s] ep 26 val mse 0.001206\n",
      "21.27419\n",
      "11.6749525\n",
      "[354.36s] ep 27 val mse 0.001377\n",
      "21.98483\n",
      "12.318442\n",
      "[366.83s] ep 28 val mse 0.001253\n",
      "21.297083\n",
      "11.842214\n",
      "[379.27s] ep 29 val mse 0.001310\n",
      "22.437815\n",
      "12.500407\n",
      "[391.73s] ep 30 val mse 0.001251\n",
      "21.207481\n",
      "11.684284\n",
      "[404.26s] ep 31 val mse 0.001358\n",
      "21.362495\n",
      "12.142027\n",
      "[416.75s] ep 32 val mse 0.001278\n",
      "21.620798\n",
      "11.970076\n",
      "[429.26s] ep 33 val mse 0.001352\n",
      "22.06023\n",
      "12.114388\n",
      "[441.80s] ep 34 val mse 0.001284\n",
      "21.31531\n",
      "12.102528\n",
      "[454.19s] ep 35 val mse 0.001200\n",
      "20.747225\n",
      "11.396936\n",
      "[466.64s] ep 36 val mse 0.001240\n",
      "21.333775\n",
      "11.856666\n",
      "[479.01s] ep 37 val mse 0.001237\n",
      "20.196848\n",
      "11.446507\n",
      "[491.34s] ep 38 val mse 0.001310\n",
      "20.950289\n",
      "12.13899\n",
      "[503.78s] ep 39 val mse 0.001253\n",
      "22.364016\n",
      "12.214763\n",
      "[516.32s] ep 40 val mse 0.001583\n",
      "23.713778\n",
      "12.942106\n",
      "[528.82s] ep 41 val mse 0.001281\n",
      "22.259253\n",
      "12.464489\n",
      "[541.15s] ep 42 val mse 0.001365\n",
      "22.572401\n",
      "12.92544\n",
      "[553.38s] ep 43 val mse 0.001239\n",
      "21.582123\n",
      "11.749859\n",
      "[565.61s] ep 44 val mse 0.001145\n",
      "21.084005\n",
      "11.632772\n",
      "[577.85s] ep 45 val mse 0.001189\n",
      "21.966537\n",
      "12.603264\n",
      "[590.06s] ep 46 val mse 0.001208\n",
      "20.721092\n",
      "11.319929\n",
      "[602.25s] ep 47 val mse 0.001460\n",
      "24.503798\n",
      "13.529799\n",
      "[614.45s] ep 48 val mse 0.001343\n",
      "21.854076\n",
      "12.013189\n",
      "[626.86s] ep 49 val mse 0.001311\n",
      "22.149187\n",
      "12.346824\n",
      "[639.24s] ep 50 val mse 0.001171\n",
      "20.809813\n",
      "11.288034\n",
      "[651.63s] ep 51 val mse 0.001219\n",
      "20.062061\n",
      "11.095646\n",
      "[663.98s] ep 52 val mse 0.001697\n",
      "24.847633\n",
      "14.292437\n",
      "[676.22s] ep 53 val mse 0.001439\n",
      "21.939886\n",
      "12.319567\n",
      "[688.44s] ep 54 val mse 0.001412\n",
      "23.726711\n",
      "13.183585\n",
      "[700.64s] ep 55 val mse 0.001225\n",
      "20.673115\n",
      "11.339244\n",
      "[712.88s] ep 56 val mse 0.001317\n",
      "21.17858\n",
      "11.633241\n",
      "[725.10s] ep 57 val mse 0.001171\n",
      "20.241625\n",
      "11.063889\n",
      "[737.33s] ep 58 val mse 0.001304\n",
      "23.175169\n",
      "12.670666\n",
      "[749.55s] ep 59 val mse 0.001450\n",
      "21.196318\n",
      "11.764998\n",
      "[761.82s] ep 60 val mse 0.001187\n",
      "20.960396\n",
      "11.4311\n",
      "[774.03s] ep 61 val mse 0.001372\n",
      "21.886932\n",
      "11.812227\n",
      "[786.24s] ep 62 val mse 0.001170\n",
      "20.656376\n",
      "11.425677\n",
      "[798.46s] ep 63 val mse 0.001327\n",
      "21.600193\n",
      "11.811937\n",
      "[810.67s] ep 64 val mse 0.001247\n",
      "21.279366\n",
      "11.547401\n",
      "[822.89s] ep 65 val mse 0.001257\n",
      "20.406954\n",
      "11.200181\n",
      "[835.09s] ep 66 val mse 0.001121\n",
      "20.2959\n",
      "11.075046\n",
      "[847.30s] ep 67 val mse 0.001139\n",
      "20.636673\n",
      "11.31248\n",
      "[859.52s] ep 68 val mse 0.001092\n",
      "20.393984\n",
      "11.101325\n",
      "[871.76s] ep 69 val mse 0.001178\n",
      "20.28655\n",
      "11.013495\n",
      "[883.97s] ep 70 val mse 0.001144\n",
      "21.586416\n",
      "11.718688\n",
      "[896.18s] ep 71 val mse 0.001118\n",
      "20.814215\n",
      "11.247247\n",
      "[908.39s] ep 72 val mse 0.001287\n",
      "21.110922\n",
      "11.660392\n",
      "[920.61s] ep 73 val mse 0.001327\n",
      "21.566956\n",
      "11.759466\n",
      "[932.82s] ep 74 val mse 0.001222\n",
      "20.69394\n",
      "11.182413\n",
      "[945.02s] ep 75 val mse 0.001232\n",
      "21.37913\n",
      "11.596794\n",
      "[957.23s] ep 76 val mse 0.001186\n",
      "21.63071\n",
      "11.666053\n",
      "[969.49s] ep 77 val mse 0.001188\n",
      "20.959217\n",
      "11.454\n",
      "[981.71s] ep 78 val mse 0.001181\n",
      "21.158682\n",
      "11.529285\n",
      "[993.93s] ep 79 val mse 0.001383\n",
      "22.946857\n",
      "12.562821\n",
      "[1006.14s] ep 80 val mse 0.001263\n",
      "21.341185\n",
      "11.664134\n",
      "[1018.41s] ep 81 val mse 0.001327\n",
      "21.258389\n",
      "11.597481\n",
      "[1030.63s] ep 82 val mse 0.001412\n",
      "21.670582\n",
      "12.270253\n",
      "[1042.84s] ep 83 val mse 0.001101\n",
      "20.417763\n",
      "11.075757\n",
      "[1055.06s] ep 84 val mse 0.001313\n",
      "20.914417\n",
      "11.340853\n",
      "test model....\n",
      "RMSE= 38.75468485695975 MAE= 22.948650791531517\n",
      "20.393984\n",
      "11.101325\n"
     ]
    }
   ],
   "source": [
    "def inverse_transform(X):\n",
    "    X = (X + 1.) / 2.\n",
    "    X = 1. * X * (1250 - 0) + 0\n",
    "    return X\n",
    "for i in range(1):\n",
    "    if __name__ == '__main__':\n",
    "        logging.basicConfig(level=logging.DEBUG,format='%(levelname)s-%(message)s')\n",
    "        # 为模型中所有超参数赋值\n",
    "        epochs = 100  # 训练的轮次数\n",
    "        batch_size = 32 # 训练批次大小\n",
    "        T = 48  # 一天内的时间片段划分\n",
    "        c_length = 6  # 临近性序列长度\n",
    "        p_length = 1  # 周期性序列长度\n",
    "        t_length = 1  # 趋势性序列长度\n",
    "        grid_height, grid_width = 32, 32  # 网格图的规格\n",
    "        flow_channel = 2 # 流量类别数\n",
    "        lr = 0.0005  # 学习率\n",
    "        external_dim = 28 #额外特征维度\n",
    "        num_res_unit = 2  # 卷积残差单元个数\n",
    "\n",
    "        # 读取训练,验证和测试数据（分别需读入临近性，周期性，趋势性，额外特征数据已经标签数据）\n",
    "        c_train = np.load('data/c_train.npy')\n",
    "        p_train = np.load('data/p_train.npy')\n",
    "        t_train = np.load('data/t_train.npy')\n",
    "        e_train = np.load('data/e_train.npy')\n",
    "        w_train = np.load('data/w_train.npy')\n",
    "        train_y = np.load('data/train_y.npy')\n",
    "        c_val = np.load('data/c_val.npy')\n",
    "        p_val = np.load('data/p_val.npy')\n",
    "        t_val = np.load('data/t_val.npy')\n",
    "        e_val = np.load('data/e_val.npy')\n",
    "        w_val = np.load('data/w_val.npy')\n",
    "        val_y = np.load('data/val_y.npy')\n",
    "        c_test = np.load('data/c_test.npy')\n",
    "        p_test = np.load('data/p_test.npy')\n",
    "        t_test = np.load('data/t_test.npy')\n",
    "        e_test = np.load('data/e_test.npy')\n",
    "        w_test = np.load('data/w_test.npy')\n",
    "        test_y = np.load('data/test_y.npy')\n",
    "\n",
    "        # 读取已保存的归一化数据转换器\n",
    "        with open ('../data_process/data/preprocessing.pkl', 'rb') as f:\n",
    "         scale = pickle.load(f)  \n",
    "        # 将训练集/验证集/测试集都整理成pytorch的输入格式\n",
    "        train_set = TensorDataset(torch.Tensor(c_train),torch.Tensor(p_train),torch.Tensor(t_train), \n",
    "                torch.Tensor(e_train),torch.Tensor(w_train), torch.Tensor(train_y))\n",
    "        val_set = TensorDataset(torch.Tensor(c_val),torch.Tensor(p_val),torch.Tensor(t_val),\n",
    "               torch.Tensor(e_val),torch.Tensor(w_val),  torch.Tensor(val_y))\n",
    "        test_set = TensorDataset(torch.Tensor(c_test),torch.Tensor(p_test),torch.Tensor(t_test),\n",
    "               torch.Tensor(e_test), torch.Tensor(w_test), torch.Tensor(test_y))\n",
    "\n",
    "        # 装载训练集/验证集/测试集数据\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle = True,drop_last=False)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle = False,drop_last = False)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle = False,drop_last = False)\n",
    "        # 定义模型\n",
    "        net = Model(lr = lr, epoch = epochs, batch_size = batch_size, \n",
    "                   c_length = c_length, p_length = p_length, t_length = t_length, \n",
    "                   external_dim = external_dim, grid_heigh = grid_height, \n",
    "                   grid_width = grid_width, flow_channel = flow_channel, \n",
    "                   num_res_unit = num_res_unit, data_min = scale._min, data_max = scale._max)\n",
    "\n",
    "        if gpu_available:\n",
    "            net = net.to(gpu)\n",
    "        # 训练模型\n",
    "        net.train_model(train_loader, val_loader)\n",
    "        print('test model....')\n",
    "        net.load_model(\"ST-D3DDARN\") # 读取最优模型\n",
    "        rmse, mae,ypred,y  = net.test_model(test_loader) #用验证集上最好的模型进行测试评估\n",
    "        y = [inverse_transform(d) for d in y]\n",
    "        ypred = [inverse_transform(d) for d in ypred]\n",
    "        y1 = np.array(y).reshape(2752512)\n",
    "        ypred1 = np.array(ypred).reshape(2752512)\n",
    "        print('RMSE', np.sqrt(metrics.mean_squared_error(ypred1, y1)))\n",
    "        print('MAE', metrics.mean_absolute_error(ypred1, y1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
